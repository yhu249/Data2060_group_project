{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Model_2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB as SklearnGaussianNB\n",
    "\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check 1: `_gaussian_log_pdf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 1.1 : Gaussian log pdf at the mean**\n",
    "\n",
    "checks that our implementation of `_gaussian_log_pdf` matches the closed-form analytical value at the mean.  \n",
    "\n",
    "For $N(0, 1)$, log pdf at $x=0$ is $-0.5 * \\log(2*pi)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed: -0.9189385332046727\n",
      "Expected: -0.9189385332046727\n",
      "Test 1.1 PASSED: gaussian_log_pdf center value correct.\n"
     ]
    }
   ],
   "source": [
    "m = GaussianNaiveBayes()\n",
    "\n",
    "val = m._gaussian_log_pdf(0.0, mean=0.0, var=1.0)\n",
    "\n",
    "expected = -0.5 * np.log(2.0 * np.pi * 1.0)\n",
    "\n",
    "print(\"Computed:\", val)\n",
    "print(\"Expected:\", expected)\n",
    "assert val == pytest.approx(expected, rel=1e-6)\n",
    "print(\"Test 1.1 PASSED: gaussian_log_pdf center value correct.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 1.2: Monotonic decay away from the mean**\n",
    "\n",
    "checks that our implementation of `_gaussian_log_pdf` gives correct Gaussian log density result that will monotonic decay as we move away from the mean.\n",
    "\n",
    "For a fixed normal distribution $N(0, 1)$, the log pdf should be highest at the mean and decrease as $|x - \\mu|$ increases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9189385332046727 -1.4189385332046727 -2.9189385332046727\n",
      "Test 1.2 PASSED: gaussian_log_pdf monotonicity correct.\n"
     ]
    }
   ],
   "source": [
    "center = m._gaussian_log_pdf(0.0, mean=0.0, var=1.0)\n",
    "off_1  = m._gaussian_log_pdf(1.0, mean=0.0, var=1.0)\n",
    "off_2  = m._gaussian_log_pdf(2.0, mean=0.0, var=1.0)\n",
    "print(center, off_1, off_2)\n",
    "\n",
    "assert center > off_1 > off_2\n",
    "print(\"Test 1.2 PASSED: gaussian_log_pdf monotonicity correct.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 1.3: Effect of the variance on the log pdf**\n",
    "\n",
    "checks that changing the variance parameter in the Gaussian distribution changes the output of `_gaussian_log_pdf`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1.3 PASSED: variance affects gaussian_log_pdf output.\n"
     ]
    }
   ],
   "source": [
    "n1 = m._gaussian_log_pdf(1.0, mean=0.0, var=0.5)\n",
    "n2 = m._gaussian_log_pdf(1.0, mean=0.0, var=5.0)\n",
    "\n",
    "assert not np.isclose(n1, n2)\n",
    "print(\"Test 1.3 PASSED: variance affects gaussian_log_pdf output.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check 2: `_compute_log_likelihood`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 2.1: calculation of log likelihood value**\n",
    "\n",
    "checks if `_compute_log_likelihood` correctly sums the per-feature Gaussian log pdfs by manually calculating total log-likelihood from a 2-dimensional toy dataset example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2.1 PASSED: compute_log_likelihood matches manual calculation.\n"
     ]
    }
   ],
   "source": [
    "m.classes_ = np.array([0])\n",
    "m.gaussian_means_[0] = {0: 0.0, 1: 1.0}\n",
    "m.gaussian_vars_[0]  = {0: 1.0, 1: 4.0}\n",
    "\n",
    "x_row = np.array([0.0, 3.0])\n",
    "log1 = m._gaussian_log_pdf(x_row[0], 0.0, 1.0)\n",
    "log2 = m._gaussian_log_pdf(x_row[1], 1.0, 4.0)\n",
    "expected = log1 + log2\n",
    "\n",
    "assert m._compute_log_likelihood(x_row, 0) == pytest.approx(expected, rel=1e-6)\n",
    "print(\"Test 2.1 PASSED: compute_log_likelihood matches manual calculation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 2.2： distance and log-likelihood**\n",
    "\n",
    "checks that samples farther from the class mean produce lower log-likelihood values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2.2 PASSED: log-likelihood decreases for far-away samples.\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array([0.0, 1.0])\n",
    "x2 = np.array([5.0, 10.0])\n",
    "\n",
    "ll1 = m._compute_log_likelihood(x1, 0)\n",
    "ll2 = m._compute_log_likelihood(x2, 0)\n",
    "\n",
    "assert ll1 > ll2\n",
    "print(\"Test 2.2 PASSED: log-likelihood decreases for far-away samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check 3: `fit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 3.1: Correct computation of class priors and class structure**\n",
    "\n",
    "checks that `fit()` correctly detects class labels and calculates the corresponding log-priors based on class frequencies. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 3.1 PASSED: fit() correctly computes priors and classes.\n"
     ]
    }
   ],
   "source": [
    "X_toy = np.array([[1,2],[1.2,1.9],[3.2,4.8],[3,5.1],[2.5,2.9]])\n",
    "y_toy = np.array([0,0,1,1,1])\n",
    "\n",
    "m.fit(X_toy, y_toy)\n",
    "\n",
    "# classes\n",
    "assert isinstance(m.classes_, np.ndarray)\n",
    "assert m.classes_.ndim == 1\n",
    "assert set(m.classes_) == {0,1}\n",
    "\n",
    "assert set(m.log_priors_.keys()) == set(m.classes_)\n",
    "\n",
    "\n",
    "N = len(y_toy)\n",
    "for c in m.classes_:\n",
    "    expected = np.log(np.sum(y_toy == c) / N)\n",
    "    assert np.isclose(m.log_priors_[c], expected)\n",
    "\n",
    "print(\"Test 3.1 PASSED: fit() correctly computes priors and classes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 3.2: Positive variances after smoothing**\n",
    "\n",
    "checks that all per-feature variances are strictly positive after smoothing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 3.2 PASSED: fit() produces positive variances.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for c in m.classes_:\n",
    "    for j in range(X_toy.shape[1]):\n",
    "        assert m.gaussian_vars_[c][j] > 0\n",
    "\n",
    "print(\"Test 3.2 PASSED: fit() produces positive variances.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 3.3: Correct structure of stored means and variances**\n",
    "\n",
    "checks that each class stores a full set of per-feature means and variances with the correct dictionary structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 3.3 PASSED: fit() structure for means/vars correct.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_features = X_toy.shape[1]\n",
    "\n",
    "for c in m.classes_:\n",
    "    assert len(m.gaussian_means_[c]) == n_features\n",
    "    assert len(m.gaussian_vars_[c]) == n_features\n",
    "\n",
    "print(\"Test 3.3 PASSED: fit() structure for means/vars correct.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 3.4: NaN in input should raise ValueError**\n",
    "\n",
    "when there's NaN value in fit() input, raise ValueError. This ValueError is included in the model since GNB could not process NaN values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 3.4 PASSED: fit raises ValueError when X contains NaN.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    X_nan = np.array([[1.0, 2.0],\n",
    "                      [np.nan, 3.0]])\n",
    "    y_nan = np.array([0, 1])\n",
    "\n",
    "    m.fit(X_nan, y_nan)\n",
    "    raise AssertionError(\"Test 3.4 FAILED: fit did not raise ValueError on NaN input.\")\n",
    "except ValueError:\n",
    "    print(\"Test 3.4 PASSED: fit raises ValueError when X contains NaN.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check 4: `predict_log_proba`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 4.1: Output shape and dtype of `predict_log_proba`**\n",
    "\n",
    "checks that `predict_log_proba` method returns the output shape (n_sample, n_classes) and dtype.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 4.1 PASSED: predict_log_proba shape + dtype correct.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test = np.array([[1.1,2.0],[3.1,4.9]])\n",
    "\n",
    "logp = m.predict_log_proba(X_test)\n",
    "assert isinstance(logp, np.ndarray)\n",
    "assert logp.shape == (2,2)\n",
    "assert logp.dtype == float\n",
    "\n",
    "print(\"Test 4.1 PASSED: predict_log_proba shape + dtype correct.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 4.2: `predict_log_proba` scores**\n",
    "\n",
    "checks that the more distant the samples, the lower the log-posterior scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 4.2 PASSED: predict_log_proba scores changes correspond to the distance.\n"
     ]
    }
   ],
   "source": [
    "lp1 = m.predict_log_proba([[1.1,2.0]])[0]\n",
    "lp2 = m.predict_log_proba([[100,100]])[0]\n",
    "\n",
    "assert lp1.max() > lp2.max()\n",
    "print(\"Test 4.2 PASSED: predict_log_proba scores changes correspond to the distance.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check 5: `predict_proba`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 5.1: Probability normalization**\n",
    "\n",
    "check that each probability row from `predict_proba` sums to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 5.1 PASSED: predict_proba rows sum to 1.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "probs = m.predict_proba(X_test)\n",
    "assert np.allclose(probs.sum(axis=1), 1.0)\n",
    "\n",
    "print(\"Test 5.1 PASSED: predict_proba rows sum to 1.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 5.2: Non negative probability**\n",
    "\n",
    "checks all values returned by `predict_proba` are non-negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 5.2 PASSED: predict_proba produces non-negative probability.\n"
     ]
    }
   ],
   "source": [
    "assert np.all(probs >= 0)\n",
    "print(\"Test 5.2 PASSED: predict_proba produces non-negative probability.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 5.3: Consistency between log-probability and probability**\n",
    "\n",
    "checks that the class with the highest log-probability also has the highest probability after normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 5.3 PASSED: predict_proba aligns with predict_log_proba.\n"
     ]
    }
   ],
   "source": [
    "# class with max log-prob = class with max prob\n",
    "logp = m.predict_log_proba(X_test)\n",
    "probs = m.predict_proba(X_test)\n",
    "\n",
    "assert np.argmax(logp[0]) == np.argmax(probs[0])\n",
    "print(\"Test 5.3 PASSED: predict_proba aligns with predict_log_proba.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check 6: `predict`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 6.1: Output shape and valid class labels**\n",
    "\n",
    "checks that `predict` returns a 1D array of valid class labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 6.1 PASSED: predict shape and value set correct.\n"
     ]
    }
   ],
   "source": [
    "preds = m.predict(X_test)\n",
    "\n",
    "assert preds.shape == (X_test.shape[0],)\n",
    "assert set(preds).issubset(set(y_toy))\n",
    "\n",
    "print(\"Test 6.1 PASSED: predict shape and value set correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 6.2: Consistency with `predict_proba`**\n",
    "\n",
    "checks that `predict` always chooses the class with the highest predicted probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 6.2 PASSED: predict matches argmax of probability.\n"
     ]
    }
   ],
   "source": [
    "probs = m.predict_proba(X_test)\n",
    "assert np.array_equal(preds, np.argmax(probs, axis=1))\n",
    "\n",
    "print(\"Test 6.2 PASSED: predict matches argmax of probability.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check 7: Edge cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 7.1: zero-variance feature**\n",
    "\n",
    "checks the case where a feature has variance 0 within each class. Confirms variance smoothing prevents divide-by-zero and that predict_log_proba()/predict_proba() remain finite and normalized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 7.1 PASSED: zero-variance features are handled correctly via variance smoothing.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_zero_var = np.array([\n",
    "    [1.0, 2.0],\n",
    "    [1.0, 3.0],\n",
    "    [1.0, 4.0],\n",
    "    [1.0, 5.0],\n",
    "])\n",
    "y_zero_var = np.array([0, 0, 1, 1])\n",
    "\n",
    "m.fit(X_zero_var, y_zero_var)\n",
    "\n",
    "logp_zero = m.predict_log_proba(X_zero_var)\n",
    "probs_zero = m.predict_proba(X_zero_var)\n",
    "\n",
    "assert np.isfinite(logp_zero).all(), \"Test 7.1 FAILED: predict_log_proba produced non-finite values with zero-variance feature.\"\n",
    "assert np.isfinite(probs_zero).all(), \"Test 7.1 FAILED: predict_proba produced non-finite values with zero-variance feature.\"\n",
    "assert np.allclose(probs_zero.sum(axis=1), 1.0, atol=1e-6), \"Test 7.1 FAILED: probabilities do not sum to ~1.\"\n",
    "\n",
    "print(\"Test 7.1 PASSED: zero-variance features are handled correctly via variance smoothing.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 7.2: Single-class training**\n",
    "\n",
    "checks that training on data with only one class does not crash and produces reasonable outputs. Ensures classes_ has length 1, predict_proba() returns probabilities ≈ 1, and predict() always returns the only class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 7.2 PASSED: model behaves correctly when trained on a single class.\n"
     ]
    }
   ],
   "source": [
    "X_one_class = np.array([\n",
    "    [1.0, 2.0],\n",
    "    [1.5, 2.5],\n",
    "    [2.0, 3.0],\n",
    "])\n",
    "y_one_class = np.array([0, 0, 0])\n",
    "\n",
    "m.fit(X_one_class, y_one_class)\n",
    "\n",
    "assert m.classes_.shape == (1,), \"Test 7.2 FAILED: classes_ should contain exactly one class.\"\n",
    "assert m.classes_[0] == 0, \"Test 7.2 FAILED: the single class in classes_ should be 0.\"\n",
    "\n",
    "probs_one_class = m.predict_proba(X_one_class)\n",
    "preds_one_class = m.predict(X_one_class)\n",
    "\n",
    "assert probs_one_class.shape == (X_one_class.shape[0], 1), \"Test 7.2 FAILED: predict_proba shape incorrect for single-class training.\"\n",
    "assert np.allclose(probs_one_class, 1.0, atol=1e-6), \"Test 7.2 FAILED: probabilities are not all ~1 for single-class training.\"\n",
    "assert np.array_equal(preds_one_class, np.zeros_like(y_one_class)), \"Test 7.2 FAILED: predict did not return the only class.\"\n",
    "\n",
    "print(\"Test 7.2 PASSED: model behaves correctly when trained on a single class.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 7.3: Single test sample**\n",
    "\n",
    "verifies shape handling and probability normalization when predicting on a single input sample. Ensures predict_proba() returns shape (1, C), sums to 1, and predict() returns a valid class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 7.3 PASSED: predict_proba/predict handle a single test sample correctly.\n"
     ]
    }
   ],
   "source": [
    "X_train_small = np.array([\n",
    "    [2.0, 3.0],\n",
    "    [3.0, 4.0],\n",
    "    [4.0, 5.0],\n",
    "])\n",
    "y_train_small = np.array([0, 1, 1])\n",
    "X_test_single = np.array([[3.5, 4.5]])\n",
    "\n",
    "m.fit(X_train_small, y_train_small)\n",
    "\n",
    "probs_test_single = m.predict_proba(X_test_single)\n",
    "pred_test_single = m.predict(X_test_single)\n",
    "\n",
    "assert probs_test_single.shape == (1, 2), \"Test 7.3 FAILED: predict_proba shape incorrect for a single test sample.\"\n",
    "assert np.allclose(probs_test_single.sum(axis=1), 1.0, atol=1e-6), \"Test 7.3 FAILED: probs do not sum to ~1.\"\n",
    "assert pred_test_single.shape == (1,), \"Test 7.3 FAILED: predict shape incorrect for a single test sample.\"\n",
    "assert pred_test_single[0] in m.classes_, \"Test 7.3 FAILED: predicted label not in known classes.\"\n",
    "\n",
    "print(\"Test 7.3 PASSED: predict_proba/predict handle a single test sample correctly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 7.4: Extreme magnitudes**\n",
    "\n",
    "tests numerical stability under very large feature values. Confirms log-sum-exp and log-space computations avoid underflow/overflow and keep outputs finite and normalized.\n",
    "\n",
    "Large values stress (x-mean)^2 / var. We only require finite outputs and normalized probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 7.4 PASSED: extreme magnitudes remain numerically stable (log-space + log-sum-exp).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_extreme = np.array([\n",
    "    [ 1e9,  -1e9],\n",
    "    [ 1e9+1, -1e9-1],\n",
    "    [-1e9,   1e9],\n",
    "    [-1e9-1, 1e9+1],\n",
    "])\n",
    "y_extreme = np.array([0, 0, 1, 1])\n",
    "\n",
    "m.fit(X_extreme, y_extreme)\n",
    "\n",
    "logp_ext = m.predict_log_proba(X_extreme)\n",
    "probs_ext = m.predict_proba(X_extreme)\n",
    "\n",
    "assert np.isfinite(logp_ext).all(), \"Test 7.4 FAILED: log-probabilities contain NaN/inf under extreme magnitudes.\"\n",
    "assert np.isfinite(probs_ext).all(), \"Test 7.4 FAILED: probabilities contain NaN/inf under extreme magnitudes.\"\n",
    "assert np.allclose(probs_ext.sum(axis=1), 1.0, atol=1e-6), \"Test 7.4 FAILED: probs do not sum to ~1 under extreme magnitudes.\"\n",
    "\n",
    "print(\"Test 7.4 PASSED: extreme magnitudes remain numerically stable (log-space + log-sum-exp).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, these tests demonstrates that each component of our Gaussian Naive Bayes implementation works correctly in isolation, handles edge cases correctly, and exactly reproduces both the predictions and probabilistic outputs of sklearn’s implementation on a real-world dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data2060",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
